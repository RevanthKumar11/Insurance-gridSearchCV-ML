{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv('insurance_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.get_dummies(dataSet,drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataSet[['age', 'bmi', 'children', 'sex_male', 'smoker_yes']]\n",
    "dependent = dataSet[['charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params = {'n_estimators':[50,100,1000,2000,3000]}\n",
    "lgm_params = {'n_estimators':[50,100,1000,2000,3000]}\n",
    "ada_params = {'n_estimators':[50,100,1000,2000,3000],'loss':['linear','square','exponential']}\n",
    "gradient_params ={'criterion':['mse','mae'],'max_features':['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgBoost = xg.XGBRegressor()\n",
    "lgBoost = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostingModel = [\n",
    "    ('XG boosting',xgBoost,xg_params),\n",
    "    ('Light boosting',lgBoost,lgm_params),\n",
    "    ('Ada boosting',AdaBoostRegressor(),ada_params),\n",
    "    ('Gradient boosting',GradientBoostingRegressor(),gradient_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:   14.9s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************** XG boosting ***********************************\n",
      "Best params {'n_estimators': 50}\n",
      "Best Score 0.8207264760534696\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    6.4s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************** Light boosting ***********************************\n",
      "Best params {'n_estimators': 50}\n",
      "Best Score 0.84773713378284\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   36.3s finished\n",
      "C:\\Users\\REVANTH KUMAR\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************** Ada boosting ***********************************\n",
      "Best params {'loss': 'linear', 'n_estimators': 50}\n",
      "Best Score 0.8311413587328459\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 517 tasks      | elapsed: 27.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************** Gradient boosting ***********************************\n",
      "Best params {'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto', 'n_estimators': 50}\n",
      "Best Score 0.8593036048727468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 34.7min finished\n",
      "C:\\Users\\REVANTH KUMAR\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for name,model,params in boostingModel:\n",
    "    regressor = GridSearchCV(model,params,refit=True,verbose=3,n_jobs=-1,scoring='r2',cv=5)\n",
    "    regressor.fit(independent,dependent)\n",
    "    print(\"*\"*35,name,\"*\"*35)\n",
    "    print(\"Best params\",regressor.best_params_)\n",
    "    print(\"Best Score\",regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
